
import numpy as np
from sklearn.decomposition import PCA
import pandas as pd 
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split


# loading dataset
dataset = pd.read_csv("dataset_x.csv",header=0)
X = dataset.loc[:,].values
dataset = pd.read_csv("dataset_y.csv",header=0)
Y = dataset.loc[:,].values

# shuffling data
indices = [i for i, y in enumerate(Y) if y == [0]]
print("Indeces for class [0] before shuffle: \n",indices)
X,Y=shuffle(X,Y)
indices = [i for i, y in enumerate(Y) if y == [0]]
print("Indeces for class [0] before shuffle: \n",indices)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

# set GPU to use it as train device
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpus[0], True)


from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt
import keras
# create our network 
model = Sequential()
model.add(Dense(512, input_dim=311, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

#compiling our model with SGD optimizer and mean squared loss function
model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])

#traing with 33% validation split
history = model.fit(X_train, y_train, epochs=20, batch_size=10,validation_split=0.33)

#save model
model.save("TRAINED_MODEL-V3.h5")

#result
print(history.history.keys())

# ploting summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# ploting summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sn
y_pred= model.predict_classes(X_test)
cm = confusion_matrix(y_test, y_pred)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

df_cm = pd.DataFrame(cmn, index = ["Non-Malware","Malware"], columns = ["Non-Malware","Malware"])
sn.heatmap(df_cm, annot=True, annot_kws={"size": 16}) # font size
plt.show()
print(cmn)




result = model.evaluate(X_test,y_test)
print("Evaluate :")
print(dict(zip(model.metrics_names, result)))
